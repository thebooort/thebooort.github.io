[{"content":"aaa\n","description":"Conferencias y talleres para Asociacion Granadina de Altas capacidades","id":3,"section":"showcase","tags":null,"title":"Conferencias y talleres para Asociacion Granadina de Altas capacidades","uri":"https://thebooort.github.io/showcase/comunicaci%C3%B3n-cient%C3%ADfica/asgran/"},{"content":"aaa\n","description":"Talleres en la Feria de la ciencia del Parque de las Ciencia (Granada)","id":6,"section":"showcase","tags":null,"title":"Talleres en la Feria de la ciencia del Parque de las Ciencia (Granada)","uri":"https://thebooort.github.io/showcase/comunicaci%C3%B3n-cient%C3%ADfica/feria_de_la_ciencia/"},{"content":"Image credit: Ivan Aleksic @ivalex Unsplash\nEste post es una actualizaci√≥n de uno m√°s antiguo, d√≥nde podr√©is encontrar informaci√≥n sobre d√≥nde encontr√© los datos, tips para dibujar el gr√°fico y qu√© significa ¬øC√≥mo afecta el confinamiento a los niveles de poluci√≥n? Durante la cuarentena que estamos viviendo la reducci√≥n de la movilidad de las personas es evidente.\nLigada a esta disminuci√≥n del tr√°nsito de vehiculos particulares, vehiculos de transporte p√∫blico y algunas maquinarias pertenecientes a servicios que se encuentran inactivos, muchos medios se han hecho eco de la disminuci√≥n en los niveles de poluci√≥n ambiental. Es m√°s, al ser COVID una enfermedad que afecta a las v√≠as respiratorias, ya hay algunos an√°lisis que relacionan la poluci√≥n del aire con tasas de moratilidad mas altas por COVID.\nPor este motivo me pareci√≥ interesante estudiar el caso de la ciudad en la que resido: Granada(Espa√±a).\nPlot  ","description":"Evoluci√≥n de los niveles de poluci√≥n en Granada durante la cuarentena (actualizaci√≥n con datos de agosto)","id":12,"section":"posts","tags":["Visualization","Data","COVID19","Python","Pollution","Ecology","Air Quality"],"title":"El aire que respiramos durante el confinamiento (actualizaci√≥n con datos de agosto)","uri":"https://thebooort.github.io/posts/pollution_levels_update_agosto/"},{"content":"photo credits: Photo by Joe Woods on Unsplash\nPlotting winning probabilities in a 19x19 Go / Baduk game From this older post:\n This morning I found this post on Reddit about winning probability for black for all starting positions.\nI found this visualization quite interested but i couldn\u0026rsquo;t find any link to a source code to generate it or the data used to generate it, so I decided to replicate it myself.\n Data This time I run last version of Leela Zero v.0.17 with Chinese counting and 7.5 komi (using my GPU). I use the gtp engine via Lizzie an try every strating position.\nI will upload the data via sfg, as Lizzie let you safe prob\u0026rsquo;s data. If I haven\u0026rsquo;t uploaded it yet and want to use the data, just send me a message.\nPlotting considerations Refer to this older post in order to know a little bit more about the code.\nResults Again, I am quite happy with the results. I think these heatmaps looks better than just adding squares to every point. It is just a matter of taste! However, I don\u0026rsquo;t LOVE the colormap. It\u0026rsquo;s close to the initial style, but the percentage variations are too extreme and I haven\u0026rsquo;t found a colormap that, in my opinion, reflects well the data (aesthetically). I know I could design one by hand to be better, but, for now, I think jet does its job.\n  with colorbar     Explicit probabilities   ","description":"Update! Heatmap of probability for black to win for all starting positions in a 19x19 board (Leela Zero GPU V0.17)","id":13,"section":"posts","tags":["Visualization","Data","Python","Machine Learning","Go","Baduk"],"title":"Winning probabilities in Go 19x19 (LeelaZero)","uri":"https://thebooort.github.io/posts/baduk-go-winning-probabilities-2/"},{"content":"  20 a√±os y 20 horas Quiero invitarte a reflexionar: ¬ød√≥nde estabas hace 20 a√±os?\nEchar la vista atr√°s tanto tiempo puede ser complicado, pero es necesario para el tema que queremos tratar hoy. En un periodo tan largo caben muchas experiencias, tanto buenas como malas. Incluso, dependiendo del lector, ese per√≠odo puede que abarque toda su existencia.\nY antes de que empieces a sentir v√©rtigo por lo r√°pido que pasa la vida y lo viejo/a que te encuentras, quiero que te quedes con esa visi√≥n de la enorme cantidad de tiempo que suponen 20 a√±os, 175.200 horas.\n20 a√±os fueron los que Charles Eug√®ne Delaunay (1816-1872), matem√°tico franc√©s, necesit√≥ para calcular la √≥rbita de la luna, intentando mejorar los intentos de sus predecesores, Laplace y Le Verrier.\nEste periodo se dividi√≥ en dos etapas de 10 a√±os, una para hacer las cuentas y otra para verificarlas. En 1847, con la p√∫blicaci√≥n de su metodolog√≠a en la revista de la Academia francesa de Par√≠s, se daba el pistoletazo de salida a una prueba calcul√≠stica que iba a requerrir mucho de Delaunay.\nLa primera parte del rompecabezas para calcular la √≥rbita de la luna fue una aproximaci√≥n. Delaunay consider√≥ las √≥rbitas de la luna y la tierra eran el√≠pticas y se encontraban en planos diferentes. Posteriormente a√±adi√≥ las perturbaciones producidas por el Sol y otros planetas, hasta obtener un sistema Hamiltoniano (un sistema de ecuaciones diferenciales que describe el movimiento de la luna). El primer paso estaba dado.\nTener el sistema y poder usarlo o resolverlo eran cosas muy distintas. La √∫nica opci√≥n que le qued√≥ a Delanay (y que sigue siendo utilizada en muchas ocasiones hoy en d√≠a) fue traducir su sistema diferencial a una expresi√≥n en suma de potencias.\nSiendo parcos en palabras, Delaunay pas√≥ de resolver un sistema de ecuaciones a calcular una suma de muchisimos t√©rminos. ¬øD√≥nde est√° el truco? Los coeficientes de esos t√©rminos deb√≠an ser obtenidos a mano mediante transformaciones algebraicas, y cu√°nta m√°s exactitud quer√≠a, m√°s t√©rminos deb√≠a poner (y por tanto, m√°s coeficientes y m√°s c√°clulos a mano). Lleg√≥ hasta orden 7, lo que se traduce en 478 t√©rminos, los cuales ten√≠an por coeficientes polinomios que tambi√©n deb√≠an ser calculados.\nEn 1867, Charles publica su segundo tomo de resultados, concluyendo su periplo celeste. Sin embargo, los resultados, aunque acertados, no ten√≠an la precisi√≥n que Delaunay esperaba, con m√°rgenes de error de hasta 100km. ¬øFue un esfuerzo en bano? ¬øSe hab√≠a equivocado Delaunay?\nTardar√≠amos casi 100 a√±os en saber que pas√≥.\nEl problema de encontrar el fallo en el trabajo de Delaunay era cuantitativo. A Delaunay le hab√≠a llevado unos 10 a√±os comprobar todos sus c√°lculos. Sin la perspectiva de que encontrar el error mejorase sus resultados enormente, nadie iba perder 10 a√±os de su vida sin garant√≠as.\nAdem√°s, hubo m√°s intentos tras Delaunay. Intentos que mejoraron sus resultados y avanzaron nuestra comprensi√≥n de la mecanica celeste y la luna.\nAsi que para resolver el misterio hubo que esperar a una de las grandes revoluciones del siglo XX: el algebra computacional y el c√°lculo simb√≥lico (vamos, que le cargamos el muerto a un ordenador, que no se queja).\nHasta 1960 los ordenadores que exist√≠an se llevaban bastante bien con las cuentas. Sumas, restas, matrices\u0026hellip; lo que en matem√°tica aplicada conocemos como c√°lculo num√©rico. Dentro de este √°rea, podemos atacar el problema de la √≥rbita lunar a traves de la integraci√≥n num√©rica (usando las funciones de nuestro sistema y operaciones b√°sicas). Desgraciadamente las aproximaciones anal√≠ticas (como la de Delaunay) que requieren transformar nuestro sistema con manipulaciones algebraicas complejas, y aunque nos dan una mejor comprensi√≥n de lo que est√° pasando, no eran programables en un ordenador.\nLo que nos permite el algebra computacional es justo eso, manipular las expresiones, trabajar con ellas, con los s√≠mbolos de la matem√°tica. Y gracias a ello resolvimos el misterio de Delaunay.\nAndr√© Deprit (1926-2006), fue uno de esos matem√°ticos pioneros que consigui√≥ que el ordenador hablase el lenguaje matem√°tico. Junto con J.M.A. Danby y Arnold Rom desarrollan un paquete matem√°tico: MAO - Mechanized Algebraic Operations. Este paquete fue un precursor en su clase, potenciando el desarrollo de muchos otros lenguajes de c√°lculo simb√≥lico (como Macsyma, el abuelo de wxMaxima o Mathematica, sin el que muchos estudiantes no pueden vivir hoy en d√≠a). Para mostrar las bondades de su trabajo, Deprit y su equipo deb√≠an escoger un problema interesante.\nGracias a la transformaci√≥n expl√≠cita basada en series de Lie, Deprit y sus colaboradores pudieron replicar todas las transformaciones algebraicas del trabajo de Delaunay, consiguieron que el ordenador hablase nuestro mismo lenguaje, con variables, coeficientes y c√°lculos itnermedios. Y todo ello, para descubrir que casi al final del sumatorio, Delanay hab√≠a confundido un 33/16 por un 23/16. Un fallo lo tiene cualquiera.\n20 horas de computaci√≥n bastaron para encontrar un error en un trabajo de 20 a√±os.\n20 horas que sirvieron para mostrar la potencia de los nuevos lenguajes de c√°lculo simb√≥lico, y la importancia que iban a tener en los a√±os venideros.\nNotas Delaunay no s√≥lo trabaj√≥ en mec√°nica celeste. Su trabajo como matem√°tico se ve reflejado en otras √°reas. Muestra de ello es un art√≠culo publicado en 1841, donde demuestra que las √∫nicas superficies de revoluci√≥n con curvatura media constante, son las superficies obtenidas por rotaci√≥n de las ruletas c√≥nica. Estas superficies se denominan actualmente, en su honor, superficies de Delaunay.\nBibliograf√≠a  La columna de la Academia (La Verdad, 9 de abril de 2016) https://www.um.es/geometria/files/Delaunay.pdf Tony Hurlimann. 1999. Mathematical Modeling and Optimization: An Essay for the Design of Computer-Based Modeling Tools. Kluwer Academic Publishers, USA. Introduction √† la th√©orie de la Lune de Delaunay https://journals.openedition.org/bibnum/683 H S Dumas, K R Meyer, D S Schmidt. 1995. Hamiltonian Dynamical Systems: History, Theory, and Applications. The IMA Volumes in Mathematics and its Applications, Springer. Deprit A, Henrard J, Rom A. Lunar Ephemeris: Delaunay\u0026rsquo;s Theory Revisited. Science. 1970 Jun 26;168(3939):1569-70. Nota Necrologica: Prof. Dr. Andre Deprit http://www.raczar.es/webracz/ImageServlet?mod=publicaciones\u0026amp;subMod=revistas\u0026amp;car=revista61\u0026amp;archivo=p181.pdf  Images credit:   Cabecera: Joseph D.M. White\u0026rsquo;s Youtube channel https://www.youtube.com/watch?v=ugxRx7alXb4\u0026amp;feature=emb_logo\n  Photo by Neven Krcmarek on Unsplash: https://unsplash.com/photos/9dTg44Qhx1Q\n  ","description":"Sobre la luna, Delaunay , Deprit y el inicio del √°lgebra computacional","id":14,"section":"posts","tags":["Comunicaci√≥n","Comunicaci√≥n Cient√≠fica","Ciencia","Divulgaci√≥n","Matem√°ticas","Algebra","Computaci√≥n","Computaci√≥n Matem√°tica"],"title":"20 a√±os y 20 horas","uri":"https://thebooort.github.io/posts/moon_maxima/"},{"content":"  Esta semilla parece una mierda La vida est√° llena de trampas, de enga√±os. No importa que tus intenciones sean buenas, o que te creas una persona muy avispada (Drunning effect warning), en alg√∫n momento te la han colado. Cada d√≠a, la sobrecarga de informaci√≥n nos dificulta tomar decisiones y formarnos una opini√≥n, dej√°ndonos a merced de que nuestro esp√≠ritu cr√≠tico decida plantar batalla y nos obligue a investigar sobre esa foto incendiaria que nos ha llegado por WhatsApp.\nSi ya es dif√≠cil para nosotros, imagin√°os para un escarabajo.\nEn particular hablamos del simp√°tico Epirinus flagellatus (Fabricius,1775) habitante de las zonas de Sud√°frica. Este escarabajo pertenece a la familia Scarabaeoidea, es decir, los com√∫nmente llamados escarabajos peloteros. El ciclo de vida de estos simp√°ticos insectos est√° estrechamente relacionado con las heces. Casi como expertos moldeadores, las especies de la familia Scarabaeoidea desgajan partes de esti√©rcol dejado por otros animales y lo moldean hasta obtener una cuasi-esfera. Vali√©ndose de sus patas traseras, transportan la \u0026ldquo;pelota\u0026rdquo; hasta el lugar donde han excavado su nido, y all√≠ depositan todas las que pueden.\nLa siguiente pregunta que mucha gente se hace al ver a estos escarabajos rodar esferas de caca (podemos llamarlas hecesferoides, por favor(?)) es qu√© motivo lleva a un animal a hacer esto. La respuesta, c√≥mo muchas veces en la naturaleza, son los ni√±os, o m√°s bien, la descendencia. En estas bolas de heces se insertar√°n m√°s adelante los huevos del escarabajo, que crecer√°n dentro de ellas aliment√°ndose bien calentitos (debido a la fermentaci√≥n del esti√©rcol).\nA simple vista, estos escarabajos llevan una vida sencilla, y parecer√≠a hasta raro que alg√∫n otro animal o planta quiera intentar enga√±ar a un insecto que pasa su vida comiendo o transportando caca. Nada m√°s lejos de la realidad. Extrayendo la parte escatol√≥gica del proceso, lo cierto es que la vida adulta de estos escarabajos se puede resumir en trasladar y enterrar. Y es algo que hacen bastante bien. ¬øY qui√©nes se pueden beneficiar al m√°ximo de esta particular actividad? Las plantas.\nAsi que imaginaos a nuestro escarabajo, transportando una bola que se parece mucho a una pelota de caca y que desde luego huele como tal. Dej√°ndola orgullosamente en su nido. Y todo para acabar descubriendo que lo que transporta, no s√≥lo no son heces, si no que adem√°s est√° demasiado duro para ser √∫til de cualquier forma: est√° transportando una semilla.\n  Ceratocaryum argenteum   El Espirinus flagelatus ha sido enga√±ado. La culpable, Ceratocaryum argenteum, una planta herb√°cea de la familia Restionaceae.\nTodas las plantas buscan expandirse y difundir al m√°ximo sus semillas por el medio. De hecho, las plantas poseen una gran cantidad de t√©cnicas con este fin, tantas, que su estudio tiene un √°rea dentro de la bot√°nica: Dispersi√≥n de los prop√°gulos.\nF√≥rmulas de dispersi√≥n hay muchas, sin embargo nos interesan aquellas que pertenecen a la zoocoria, aquella en la que el agente que realiza el transporte de las semillas es un animal. A este apartado pertenece nuestra culpable, la C.argenteum, que produce una particular semilla de tama√±o similar a las heces de ant√≠lope. Esta semilla, para completar el disfraz, emite vol√°tiles que se han encontrado en las deposiciones de estos herb√≠voros (se decir, \u0026ldquo;huelen\u0026rdquo; muy similar). Ante tal intrincado ardiz, el E.flagellatus no puede m√°s que caer en la trampa.\n  a.) y b.) muestran una semilla de C.argentum. f.) Esp√©cimen de E.flagellatus. g.) Heces de ant√≠lope   Es conveniente resaltar que el escarabajo no consigue nada de este transporte, no hay una relaci√≥n de mutuo beneficio. La C.argentum se vale de una exquesita t√©cnica de biom√≠mesis (o biomim√©tica) afilada a la luz de la evoluci√≥n. Este particular recurso se describi√≥ por primera vez en 2015 y es √∫nico en sus caracter√≠sticas. De hecho, la dispersi√≥n de estas semillas era un misterio, habitualmente atribuida a los roedores, pero sin pruebas que lo sustentase.\nAl final, tuvieron que llegar los escarabajos, expertos en la materia (fecal), para mostrarnos que al igual que no es oro todo lo que reluce, no es caca todo lo que rueda.\nBibliograf√≠a   Jingshang CHE,Hailong SUN,Chenjie XIAO, et al. Why information overload damages decisions? An explanation based on limited cognitive resources[J]. Advances in Psychological Science, 2019, 27(10): 1758-1768.\n  Soroush Vosoughi, Deb Roy, Sinan Aral. The spread of true and false news online. Science, 09 Mar 2018 : 1146-1151\n  Burger BBV. First Investigation of the Semiochemistry of South African Dung Beetle Species. In: Mucignat-Caretta C, editor. Neurobiology of Chemical Communication. Boca Raton (FL): CRC Press/Taylor \u0026amp; Francis; 2014. Chapter 3. Available from: https://www.ncbi.nlm.nih.gov/books/NBK200987/\n  Midgley, J. J., White, J. D., Johnson, S. D., \u0026amp; Bronner, G. N. (2015). Faecal mimicry by seeds ensures dispersal by dung beetles. Nature Plants, 1: 1-3.\n  BYRNE, MARCUS, and HELEN LUNN. Dance of the Dung Beetles: Their Role in Our Changing World. Wits University Press, 2019. JSTOR, www.jstor.org/stable/10.18772/12019042347.\n  Post donde descubr√≠ la noticia: https://www.kew.org/read-and-watch/deceiving-seed-dispersal\n  Images credit:  Cabecera: Joseph D.M. White\u0026rsquo;s Youtube channel https://www.youtube.com/watch?v=ugxRx7alXb4\u0026amp;feature=emb_logo Foto de la C.argenteum Gif y foto del estudio sobre el E.flagellatus: Midgley, J. J., White, J. D., Johnson, S. D., \u0026amp; Bronner, G. N. (2015). Faecal mimicry by seeds ensures dispersal by dung beetles. Nature Plants, 1: 1-3.  ","description":"Sobre escarabajos cegatos y plantas mal√©volas","id":15,"section":"posts","tags":["Comunicaci√≥n","Comunicaci√≥n Cient√≠fica","Ciencia","Divulgaci√≥n","Biolog√≠a"],"title":"Esta semilla parece una mierda","uri":"https://thebooort.github.io/posts/poop_and_seeds/"},{"content":"Image credit: Asociaci√≥n espa√±ola de Comunicaci√≥n cient√≠fica\nCienciaEnRedes2020 Las palabras importan: Leonor Parcero La primera charla que destaco es la ofrecida por Leonor Parcero L√≥pez de la Universidad de Vido . De esta charla he sacado unas cu√°ntas ideas que creo que son interesantes. Algunas no son nuevas, y ya hab√≠a reflexionado sobre ellas antes, pero conviene tenerlas en cuenta y volver a ellas siempre que sea necesario.\nEn primer lugar y como reflexi√≥n general, debemos tener en cuenta qu√© hacemos y c√≥mo llamamos a lo que hacemos. El problema de la notaci√≥n no es ajeno a las matem√°ticas, la buena definici√≥n de cu√°l es nuestra actividad constituye el primer paso para entenderla adecuadamente, pero tambi√©n para planificarla, sacar el m√°ximo rendimiento y, en un fin √∫ltimo, acreditarla en aquellos procedimientos que lo requieran. Habr√©is notado que he omitido la palabra coumincaci√≥n cient√≠fica (o similares). El motivo es sencillo: creo que esa reflexi√≥n es transversal y √∫til para muchisimas √°reas (mas generales o m√°s espec√≠ficas).\nEn segundo lugar destaco la notaci√≥n que Leonor describe dentro del √°mbito de la comunicaci√≥n. Las diferencias entre las √°reas est√°n bien expuestas, y me parece una notaci√≥n muy interesante para decidir el enfoque que quieras darle a tu comunicaci√≥n cient√≠fica (el mapa lo traza teniendo en cuenta objetivos, canales y p√∫blicos). Reproduzco aqu√≠ el mapa conceptual y os comento brevemente la descripci√≥n que da Leonor:\n Difusi√≥n: Contar los resultados de la investigaci√≥n. Su objetivo ser√≠a un p√∫blico preparado y/o experto, ya sea cient√≠ficos en el √°rea o en campos similares, industria, gobierno, responsables de tomas de decisiones en instituciones cient√≠ficas y medidadores (periodistas y divulgadores).\nTradicionalmente se hablaba de la misma solo en congresos cientificos, pero parece haber una ampliaci√≥n de su significado. Divulgaci√≥n: Contar conocimiento cient√≠fico a un p√∫blico lego en la materia. Con lenguaje c√≥digos y medios compartidos con ella (de forma atractiva/entretenida). Se suele usar en su lugar cultura cient√≠fica. Los objetivos pueden ser varios (participacion ciudadana, fomento vocacional, diversion, etc) Periodismo cient√≠fico: Especialidad period√≠stica centrada en contar hechos sobre ciencia y tecnolog√≠a. Caben nuevas investigaciones, pero tambi√©n hechos relevantes del sector. Es, por encima de todo, periodismo (con sus caracter√≠sticas). Algunos productos podr√≠an considerarse divulgativos.  Reflexi√≥n interesante: Vale que queramos divulgar proyectos, pero, debemos preguntarnos sobre el p√∫blico destinatario, sobre el mensaje, el medio, etc. Estas preguntas son clave y debemos hacerlas antes de comenzar a divulgar sobre nuestros proyectos. No hay que olvidar que no s√≥lo es un trabajo duro consolidar una comunidad, si no tambi√©n mantenerla.\nDivulgar sin aspavientos, ahora m√°s que nunca: Marta Macho Otra de las charlas que me gustar√≠a destacar es la de Marta Macho, investigadora de la Universidad del Pa√≠s Vasco. M√°s que analizarla, me parece una charla para disfrutarla. Estoy muy deacuerdo con muchas de las cosas que comenta Marta, es una ponente magn√≠fica. Me quedo con algunos momentos que quiz√°s sean espont√°neos, pero su dicci√≥n y cadencia de palabras y frases me encanta. No se si ser√° improvisado, pero su forma de transmitir la tengo en cuenta mientras encuentro la m√≠a.\n Cuando divulgas, debes estar formado en ese tema. Debes conocer los subterfugios de la teor√≠a para acceder a las claves y poder contestar a las preguntas que te hagan, para tender nuevos caminos a esas respuestas. Divulgar es ayudar a descubrir. No estas dando clase, si no transmitir las claves, motivar a saber m√°s. Rigor, humildad, sin prepotencia y admitir que no lo sabes todo. El humor es un medio para emocionar con ciencia, pero el humor es en parte, cultural, por lo que tu mensaje puede no llegar a su destinatario.  Marta comenta que su manera de divulgar favorita es el directo, que permite cambiar, improvisar, adaptar el mensaje a su destinatario. Aboga por una divulgaci√≥n en privado, en peque√±os grupos, donde la interacci√≥n est√© servida.\nExperiencias bajo sospechas y verdades relativas: Joaqu√≠n sevilla ¬øQu√© camino hay entre las evidencias cent√≠ficas y las decisiones sociales y/o pol√≠ticas? ¬øQu√© relevancia social aparece en ese camino? Joaqu√≠n Sevilla de la Univesidad de Navarra propone una visualizaci√≥n que me ha gustado mucho basada en tri√°ngulos.\nEse camino de agregaci√≥n de conocimiento, que parte de la certeza cient√≠fica pero a medida que avanza se ve asaltado por aspectos sociales, culturales e imprecisiones de todo tipo, a veces es m√°s largo o m√°s pque√±o. Cuando el camino es largo y necesitamos una integracion multidisciplinar que permea en muchos aspectos sociales como la pol√≠tica, es habitual que aparezcan bifucaciones (por interpretaciones culturales) que se alejan a medida que el camino avanza. Si esas interpretaciones dejan de estar cimentadas en la evidencia cient√≠fica aparece la pseudociencia.\nTomar una decisi√≥n social:\n no es evidente. no es exclusivamente cient√≠fico. Debe provenir de una agregaci√≥n de conocimiento. Supone una incorporaci√≥n de valores.  Comunicaci√≥n de la ciencia, consideraciones sociales:\n Nivel de certeza buscado (posicionarse) Evaluar la complejidad del camino (cuanto m√°s lejos, m√°s necesario es agregar voces y posiciones) Respeto a la cultura del receptor (modelo adaptativo de la comunicacion cient√≠fica) Fraude por conflictos de intereses.  Me quedo con ganas de ahondar en el modelo adaptativo de la comunicaci√≥n cient√≠fica, quiz√°s os caiga post del tema.\n","description":"Algunos apuntes que he tomado de las charlas de CienciaEnRedes2020","id":16,"section":"posts","tags":["Comunicaci√≥n","Comunicaci√≥n Cient√≠fica","LaTeX","Ciencia","Divulgaci√≥n"],"title":"Algunos apuntes de CienciaEnRedes2020","uri":"https://thebooort.github.io/posts/cienciaenredes1/"},{"content":"Image credit: Ivan Aleksic @ivalex Unsplash\nEste post es una actualizaci√≥n de uno m√°s antiguo, d√≥nde podr√©is encontrar informaci√≥n sobre d√≥nde encontr√© los datos, tips para dibujar el gr√°fico y qu√© significa ¬øC√≥mo afecta el confinamiento a los niveles de poluci√≥n? Durante la cuarentena que estamos viviendo la reducci√≥n de la movilidad de las personas es evidente.\nLigada a esta disminuci√≥n del tr√°nsito de vehiculos particulares, vehiculos de transporte p√∫blico y algunas maquinarias pertenecientes a servicios que se encuentran inactivos, muchos medios se han hecho eco de la disminuci√≥n en los niveles de poluci√≥n ambiental. Es m√°s, al ser COVID una enfermedad que afecta a las v√≠as respiratorias, ya hay algunos an√°lisis que relacionan la poluci√≥n del aire con tasas de moratilidad mas altas por COVID.\nPor este motivo me pareci√≥ interesante estudiar el caso de la ciudad en la que resido: Granada(Espa√±a).\nPlot  Conclusions! La tendencia visible ya es muy destacable. Los niveles est√°n muy reducidos frente al a√±o anterior. Puede que tengamos un peque√±o repunte que podemos correlacionar con el fin del confinamiento m√°s estricto, pero a√∫n as√≠ los niveles siguen muy bajos y, desde luego, son buenas noticias.\n","description":"Evoluci√≥n de los niveles de poluci√≥n en Granada durante la cuarentena (actualizaci√≥n con datos de abril)","id":17,"section":"posts","tags":["Visualization","Data","COVID19","Python","Pollution","Ecology","Air Quality"],"title":"El aire que respiramos durante el confinamiento (actualizaci√≥n con datos de abril)","uri":"https://thebooort.github.io/posts/pollution_levels_update_abril/"},{"content":"  We can go for a quick run, but\u0026hellip; where? From now on (technically May 2nd), in Spain (specifically in my city Granada), we are allowed to go for a quick run or walk in the morning. Those are really good news for every runner and trail runner I know, but with great power comes great responsability.\nMy main concern about going outside for a quick run is how many people will I encounter while running. The social distance that we should keep between other dramatically increase when practicing sports, as this article of urban physiscs says:\nOn the basis of these results the scientist advises that for walking the distance of people moving in the same direction in 1 line should be at least 4‚Äì5 meter, for running and slow biking it should be 10 meters and for hard biking at least 20 meters. Also, when passing someone it is advised to already be in different lane at a considerable distance e.g. 20 meters for biking.\n  Image from: Towards aerodynamically equivalent COVID-19 1.5 m social distancing for walking and running. Blocken,B. et al (2019-Preprint)   After reading all the information, next step is to enumerate all the parameters I have to take into account when designing a gps track for run training.:\n  I think it can be quite hard to take into account the running distance (10 meters can be hard to estimate while constant movement). Furthermore if you add more people to the equation, complexity increases exponentially (well, this need to be proven, but you get the point üëÖ). So my main idea is to go for a run quite early in the morning or quite late in the night, trying to minimize the number of people that can be affected by my exercises (or that can affects my health).\n  Other thing to take into account is that there is not distance limit within the city, so I have the entire city to choose where to go, that is really great for me as I don\u0026rsquo;t like to run in circle multiples times. The final running track then, can be reaching one point and coming back or some kinf of circular track.\n  No more than 5-6 kilometers the first day (we need to take it easy those first days!).\n  The first point of these is the one harder to analyze:\nAs there is no distance limits,I really think there will be probably tons of people running along their old and known tracks (I was thinking about it myself, because running in a familiar route is easier and you can adjust your exercise according to how you feel/your pace/your goals, etc), so if I want to avoid them I just have to choose those streets with less \u0026ldquo;runner-traffic\u0026rdquo;.\nHow do I do that? Well well,let\u0026rsquo;s use some data science on it!\nGetting the data I made some research about public datasets available about mobility inside my city. However (big ironic surprise) there is not a single data about mobility. So I had to change my strategy.\nStrava Raw data for this task is very hard to obtain. I remembered that Strava published a global heatmap with useful information. This heatmap shows \u0026lsquo;heat\u0026rsquo; made by aggregated, public activities over the last two years, classified by sport and it is updated monthly. This address two points: been able to use the data now, and bee able to adjust my conclusions in a month if anything changes.\n  Strava map (accessed April 30)   Sadly, I only can get visual information from it. You are forced to purchase an app create by strave to get all the data, and I am not that rich (or have time to fight with bureocracy to get a deal). If any of you knows any interesting dataset related to this task, please let me know!\n  Strava map (accessed April 30)   Garmin Garming offers another similar heatmap. I first talk about Strava because, as far as I am concern, to check the Garmin heatmap you need to be registered and have a Garmin dispositive.\nThe map can be consulted at you personal account. The main difference (strictly for me ) is that Garmin allow me to mark a track while I am consulting the map, and upload this GPS track to my watch.\nFor that reason I am going to use primarly Garmin data, but in this post y also analyze Strava data-\nAnalyzing the data Strava I live near calle San Juan de Dios so I will set my start goal over there. I zoom into the map to see what I have near my spot:\n  Strava map (accessed April 30)   No surprises here, common and bigger streets are often used by other runners. Taking into account where I am going to start, I should try to minimize the most \"common\" streets, this means that Gran Via, Avenida Fuente Nueva, Calle Reyes Cat√≥licos y Camino de Ronda mostly delimit possible tracks. Small streets inside the previous demarcations are very uncommon, so I should try to wander through streets like calle Buensuceso or Calle P√°rraga. In addition crossing hot-points like recogidas would aloow me to make a bigger circuit while minimizing my exposure. However, I have to be carefull with crossing other common routes like Camino de Ronda, as it only leads to more common spots.\nGarmin Let\u0026rsquo;s see Garmin\u0026rsquo;s data instead. One of the things I like is the way Gramin presents the information. Data don\u0026rsquo;t blott street info and the detail level is very high.\n  Garmin map (accessed April 30)     Garmin map (accessed April 30)   About the analysis I can make about the map, it is more or less the same as in Strava. Taking into account that both resources show the same information I am confident about the data signification (although the data may overlaps, as Garmin offers the option to upload track from strava.\nFinally I think I have enough information to make an useful track for my next running sessions.\nConclusions! Taking into account the previos information I design the following track.\n  Garmin map (accessed April 30)   As it is my first running session after a long time, I limit the total distance to 5km (I introduce manually the time per kilometer, but it may change depending on my sensations, however I expect to run slowly at least the first week). Almost every meter of the track goes in \u0026ldquo;low-frequency\u0026rdquo; streets where I think I won\u0026rsquo;t encounter other runner. There are 4 main points that cross \u0026ldquo;high-frequency\u0026rdquo; places, but I think the exposure (with social distance and the schedule I am planning) will be low.\nDo you need to do all of this with your sessions? Obiously no. If know which street avoid, but it is not always easy to choose an alternative track. I like to make my decissions with some amount of data to be as objetive as possible.\nIf you have any ideas, corrections or suggestions, let me know!\nImages credit:  Photo by Flo Karr on Unsplash Photo by Chander R on Unsplash  ","description":"Analyzing Strava data to know where to run with less human contact","id":18,"section":"posts","tags":["Visualization","Data","Python","Running"],"title":"Where to run after confinement?","uri":"https://thebooort.github.io/posts/where-to-run/"},{"content":"photo credits: Photo by Joe Woods on Unsplash\nPlotting winning probabilities in a 9x9 Go / Baduk game This morning I found this post on Reddit about winning probability for black for all starting positions.\nI found this visualization quite interested but i couldn\u0026rsquo;t find any link to a source code to generate it or the data used to generate it, so I decided to replicate it myself.\nI am starting with a 9x9, because I am not familiar with any parser to exchange data with a go engine. Next step is to make all process via a python script and been able to replicate all boards.\nThis quick project take me just one hour, and I am sure everything can be automated or made better, but at the end you have the data and the code, so feel free to upgrade or change anything you want.\nData For the data I just run Leela v.0.11.0 with Chinese counting and 7.5 komi. I use the gtp engine with Sabaki an try every strating position.\nPlotting considerations I get the board from this question in stackoverflow, I simply add star points and different configurations (one for plotting with color bar and other with numbers or without them.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # with colorbar #fig = plt.figure(figsize=[13,10.5]) # with numbers fig = plt.figure(figsize=[8,8]) fig.patch.set_facecolor((1,1,.8)) ax = fig.add_subplot(111) # draw the grid for x in range(9): ax.plot([x, x], [0,8], \u0026#39;k\u0026#39;) for y in range(9): ax.plot([0, 8], [y,y], \u0026#39;k\u0026#39;) # scale the axis area to fill the whole figure ax.set_position([0,0,1,1]) # get rid of axes and everything (the figure background will show through) ax.set_axis_off() # scale the plot area conveniently (the board is in 0,0..18,18) ax.set_xlim(-1,9) ax.set_ylim(-1,9) # draw star points s1, = ax.plot([2,6,6,2,2,4],[2,2,6,2,6,4],\u0026#39;o\u0026#39;, markersize=10, markeredgecolor=(0,0,0), markerfacecolor=\u0026#39;k\u0026#39;, markeredgewidth=2)   Also, I think data could be better but, adding points and values like array let me easily plot every point, been able to plot labels if I want and been able to add simply the colormap.\nResults I am quite happy with the aesthetic of the results. I think these heatmaps looks better than just adding squares to every point. It is just a matter of taste! At least you have all the data and the code to make similar things or your own variations. üòÑS\n  with colorbar     Explicit probabilities   Todo  Exchange (with a parser) data beetween python and go engine Replicate for 13x13 and 19x19  Source code and Data 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84  #!/usr/bin/env python3 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; Created on Sun Apr 26 \u0026#34;\u0026#34;\u0026#34; import matplotlib.pyplot as plt import numpy as np # create a 8\u0026#34; x 8\u0026#34; board # with colorbar #fig = plt.figure(figsize=[13,10.5]) # with numbers fig = plt.figure(figsize=[8,8]) fig.patch.set_facecolor((1,1,.8)) ax = fig.add_subplot(111) # draw the grid for x in range(9): ax.plot([x, x], [0,8], \u0026#39;k\u0026#39;) for y in range(9): ax.plot([0, 8], [y,y], \u0026#39;k\u0026#39;) # scale the axis area to fill the whole figure ax.set_position([0,0,1,1]) # get rid of axes and everything (the figure background will show through) ax.set_axis_off() # scale the plot area conveniently (the board is in 0,0..18,18) ax.set_xlim(-1,9) ax.set_ylim(-1,9) # draw star points s1, = ax.plot([2,6,6,2,2,4],[2,2,6,2,6,4],\u0026#39;o\u0026#39;,markersize=10, markeredgecolor=(0,0,0), markerfacecolor=\u0026#39;k\u0026#39;, markeredgewidth=2) b = np.array([[ 24.45, 29.95, 31.51, 32.48, 33.11, 32.48, 31.51, 29.95, 24.45], [ 29.95, 37.32, 40.28, 41.36, 40.8 , 41.36, 40.28, 37.32, 29.95], [ 31.51, 40.28, 44.5 , 45.46, 46.13, 45.46, 44.5 , 40.28, 31.51], [ 32.48, 41.36, 45.46, 48.79, 48.03, 48.79, 45.46, 41.36, 32.48], [ 32.48, 41.36, 45.46, 48.79, 48.03, 48.79, 45.46, 41.36, 32.48], [ 33.11, 40.8 , 46.13, 48.03, 48.03, 48.03, 46.13, 40.8 , 33.11], [ 31.51, 40.28, 44.5 , 45.46, 46.13, 45.46, 44.5 , 40.28, 31.51], [ 29.95, 37.32, 40.28, 41.36, 40.8 , 41.36, 40.28, 37.32, 29.95], [ 24.45, 29.95, 31.51, 32.48, 33.11, 32.48, 31.51, 29.95, 24.45]]) y_array = np.array([[ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8], [ 0,1,2,3,4,5,6,7,8]]) x_array = np.array([[ 0,0,0,0,0,0,0,0,0], [ 1,1,1,1,1,1,1,1,1], [2,2,2,2,2,2,2,2,2], [ 3,3,3,3,3,3,3,3,3], [ 4,4,4,4,4,4,4,4,4], [ 5,5,5,5,5,5,5,5,5], [ 6,6,6,6,6,6,6,6,6], [ 7,7,7,7,7,7,7,7,7], [ 8,8,8,8,8,8,8,8,8]]) #plt.colorbar() plt.title(r\u0026#39;Winning probabilities for black for all starting positions (Leela v0.11.0)\u0026#39;,fontsize=18) s1 = ax.scatter(x_array,y_array,c=b,s=3000,cmap=\u0026#39;rainbow\u0026#39;) for i in range(0,9): for j in range(0,9): s5 = ax.text(i, j, str(b[i,j]),horizontalalignment=\u0026#39;center\u0026#39;, fontsize=12,color=\u0026#39;white\u0026#39;,fontweight=\u0026#39;bold\u0026#39;)   ","description":"Heatmap of probability for black to win for all starting positions (Leela V0.11.0)","id":19,"section":"posts","tags":["Visualization","Data","Python","Machine Learning","Go","Baduk"],"title":"Winning probabilities in Go (leela)","uri":"https://thebooort.github.io/posts/baduk-go-winning-probabilities/"},{"content":"Image credit: La Tercera\n  Counter Strike and Data Science 1: Grenades and other utilities Counter Strike Global Offensive (CSGO) is a first person shooter game developed by Valve and Hidden Path Entertainment.\nThe game pits two teams against each other: the Terrorists and the Counter-Terrorists. Both sides are tasked with eliminating the other while also completing separate objectives. The Terrorists, depending on the game mode, must either plant the bomb or defend the hostages, while the Counter-Terrorists must either prevent the bomb from being planted, defuse the bomb, or rescue the hostages.\nIn competitive mode, 30 rounds are played, first team to get 16 victories wins.\nDuring COVID19 quarentine some friends invite me to play for the first time, and, despite I am not even close to good at it, I have a lot of fun playing it. After my first 10 wins, when I understood the game strategies a little bit more, I began to wonder if my positioning were good or if I was able to use grenades and other utilities correctly. So I decided to approach possible answers to this question with data science.\nIn this first part I\u0026rsquo;m going to analyze where and how to throw grenades, as I do not use them at all.\nUtilities (data from eSports team Dignitas )\nThe grenades that I am going to analyze are:\n The Flashbang  The flashbang, or flash, has the primary use of blinding opponents. If people look directly at it, teammate or not, the person who looked at it will be blinded for a period of time, defined by how close the flash popped and how directly the person looked at it.\n The Smoke Grenade  The smoke grenade instantly creates a thick, medium-sized (288 units diameter, or 144 units radius) smoke screen that lasts for 18 seconds after the fuse expires. The smoke screen is largely opaque except at the corners, blocking players\u0026rsquo; vision. If a player enters the smoke, the player\u0026rsquo;s weapon model will fade slightly and all vision will be obscured, even at zero range.\n The Molotov/Incendiary Grenade  This grenade explodes after a certain amount of time has passed after you have thrown it. If it explodes on, or close to, the ground (or any other flat surface) it will cover a good amount of space in flames. Everyone standing in those flames with 100 HP has roughly three and a half seconds left to get out of it before they die.\n Interaction between grenades:\nIt should be noted that you can put out any flames caused by an incendiary or a molotov with a smoke grenade, which may allow the CTs to survive longer than intended. There are no other interactions between any of them.  There more grenades, but I have been told that these are the ones that I should master first.\nGetting the data The map I am currently playing in competitive CSGO is inferno. It is not the most common map, but definetly top 5 maps. There are not specific reasons for this choice: my friends know this map relatively well and they know some strategies, so when I decide to play with them they choose this map.\n  de_inferno competitive map structure     Data from my game   I tried different ways to get my data from the game. But, at the end, most of the csgo stats webpages offer a huge amount of information with only the game_id. I realize that this was the easiest way to get my data. Meanwhile as I have access to other csgo datasets I can develop the code needed to plot and analyze all csgo data in case I am able to get my stats in the future. Sadly, for this part, I realize that I do not throw any grenade during the game (couple of smokes) so I will add them for visualization purpouses but they wont give as any information.\n  Data from professional players   With my personal data I can analyze my plays, but it is hard to judge them. I realized that comparing them with the usual plays that people in competitive mode would offer me more information. For this pourpose I find a dataset with ~ 1400 competitive matches, in kaggle obiously. That data is well formated and it is quite easy to work with.\nLocation names in Inferno In order to manage a common vocabulary and to understand my conclusions and analysis here you have the location names in the map (from (https://guides.gamepressure.com/counter_strike_global_offensive/guide.asp?ID=43283)):\n  Analyzing professional players data Heatmaps: You have to take into account that \u0026ldquo;radar\u0026rdquo; or \u0026ldquo;in-game\u0026rdquo; coordinates are not useful in order to plot your whateverstats-heatmap. For that purpose you have to scale the data into your image resolution. Beware that some points are beyond your image (for example some smokes are thrown away outside the map, and that could make some data noisy.\nFor de_inferno map, you have to make slighty deviations from a code I founded. Also you have to find the exact measures of your map, check the link in the code for that :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # Code modified from the one used by billfreeman44 | See his kernel : https://www.kaggle.com/billfreeman44/finding-classic-smokes-by-t-side-on-mirage  # map data: https://github.com/akiver/CSGO-Demos-Manager/tree/master/Core/Models/Maps def pointx_to_resolutionx(xinput,startX=-2222,endX=3561,resX=1160): sizeX=endX-startX if startX \u0026lt; 0: xinput += startX *(-1.0) else: xinput += startX xoutput = float((xinput / abs(sizeX)) * resX); return xoutput-15 def pointy_to_resolutiony(yinput,startY=-1649,endY=4408,resY=1250): sizeY=endY-startY if startY \u0026lt; 0: yinput += startY *(-1.0) else: yinput += startY youtput = float((yinput / abs(sizeY)) * resY); return resY-youtput-120   I change a little bit the scale and exes elevation. The results were pretty good and coherent. In this situation, it is necesary to plot the map below the plots, otherwise data could not be easy to analyze:\n1 2 3 4 5 6 7 8 9 10  # Code modified from the one used by billfreeman44 | See his kernel : https://www.kaggle.com/billfreeman44/finding-classic-smokes-by-t-side-on-mirage  im = plt.imread(\u0026#39;../input/de_inferno.png\u0026#39;) plt.figure(figsize=(15,15)) t = plt.imshow(im) t = plt.scatter(csgo_sm_small[\u0026#39;grenade_xpos\u0026#39;], csgo_sm_small[\u0026#39;grenade_ypos\u0026#39;],alpha=0.05,c=\u0026#39;blue\u0026#39;) t = plt.scatter(csgo_sm_small[\u0026#39;att_xpos\u0026#39;], csgo_sm_small[\u0026#39;att_ypos\u0026#39;],alpha=0.05,c=\u0026#39;red\u0026#39;) # we can also plot trayectories for i in range(1,len(grenade_number)): t = plt.plot([a_x[i],nade_x[i]],[a_y[i],nade_y[i]],c=\u0026#39;y\u0026#39;,alpha=0.25,linestyle=\u0026#39;dashed\u0026#39;)   With this simple steps we can get a lot of information about this map and how grenades are thrown. We will analyze the data from both team, as their strategies are different.\nCounterTerrorist side In this map counterterrorist (CT) must either prevent the bomb from being planted or defuse the bomb. They can also win if they eliminate the other team and no bomb is planted.\nFor that reason, CT in most cases, want to impede Terrorist(T) to enter to A o B zone (see the previous map if you are not familiar with those names).\nCounterTerrorist flash grenades First we have flash grenades. Here you have two plots, one with thrower and grenade final location and one with the trajectories (intensity of color can be related to the commoness of the data, more intensity means more common to appear in the dataset):\n  Flash grenades locations (blue) and Thrower location (red)     Flash grenades locations (blue) and Thrower location (red)   Seeing both plots, the most used flash are thrown to Middle an Banana, in order to difficult Terrorist advance. One should take into account those which are thrown in apartments from inside LongHall and from Balcony and Pit. These last positions are the most common for me, so I take note about these flashes.\nAlso there are some interesting flashes thrown from Garden into Sanbags and Porch, mostly to blind Terrorist if they are reaching B. There can be seen two classic postitions in the map for CT, one covering Close side, and other in Patio.\nCounterTerrorist incendiary grenades Again, I am using two plots, one with thrower and grenade final location and one with the trajectories (intensity of color can be related to the commoness of the data, more intensity means more common to appear in the dataset):\n  Incendiary grenades locations (blue) and Thrower location (red)      Incendiary grenades locations (blue), tajectory (yellow) and Thrower location (red)    Most incendiary grenades are thrown in Banana to stop Terrorist to reach B. There are also some representative throws from middle, but this position is quite unsafe for CT (they are too exposed to long-range weapons in Middle ) so I am puzzle about this specific play.\nFrom my perspective, most incendiary grenades thrown into apartments came from Point A, and Balcony. I can\u0026rsquo;t move that far during the game, so I should focus myself on thrown only when I am inside Balcony.\nCounterTerrorist smoke grenades   Smokes grenades locations (blue) and Thrower location (red)     Incendiary grenades locations (blue), tajectory (yellow) and Thrower location (red)    Smokes are usually thrown into middle, I guess that if Terrorist can\u0026rsquo;t reach Point B, them they are forced to go Point A, and CT deploy a smoke grenade to being able to create some advantages in these situations.\nIn Banana, most smokes are thrown near Sandbags, which I think are mostly a late game strategy to slow down Terrorist or a deceive strategy, making Terrorist unable to see Incendiary grenade fire.\nTerrorist side In this map terrorist (T) must plant the bomb. They can also win if they eliminate the other team and no bomb is planted.\nFor that reason, T in most cases, want to access as fast as possible to either Point A or Point B (there is limited time every round and if they do not do anything in this time, they lose).\nTerrorist flash grenades   Flash grenades locations (blue) and Thrower location (red)     Incendiary grenades locations (blue), tajectory (yellow) and Thrower location (red)   Talking about Flash grenades, T usually throw a lot of these grenades on Banana. I guess that if CT do not throw any fire, T can get some advantage blinding long-range weapons that can be on porch, end of Banana, or even Logs.\nAnother hot point is end of Middle, those grenades are useful to counter the common smoke used by CT. With those grenades T can try to eliminate anyone on Close or Patio.\nFinally, on apartments, there is some throws from outside to Window (but Incendiary are more common than flashes), and other throw to Pit and Balcony, as a way to enter safely into Point A.\nTerrorist incendiary grenades   Incendiary grenades locations (blue) and Thrower location (red)     Incendiary grenades locations (blue), tajectory (yellow) and Thrower location (red)   Incendiary grenades on T side are used in different points but with similar expected outcomes.\nFrom balcony to Pit: those are used to kill enemys at Pit.\nFrom AltMiddle to Window: prevent CT to enters this room and kill any T in this street.\nFrom Banana: stop any rush from behind when T go to PointA\nFrom Sandbags to Garden: Securing PointB and stopping any player on Garden.\nTerrorist smoke grenades   Smokes grenades locations (blue) and Thrower location (red)     Incendiary grenades locations (blue), tajectory (yellow) and Thrower location (red)   Finally smokes are used by T as a way to stop or slow down CT when they are on different positions. A lot of thes smokes prevent long range weapons to attack from middle. On other side, a lot of smokes are also played creating a barrier between Well and PointB, so CT comming this way are stopped. On pointA there some relevant smokes too, securing pointA when T have reached it. Conclusions! So far so good! I definetly have to train how to throw smokes and where to throw them, but now I have a general idea of what smokes are usually thrown (despite 1vs1 situations). Can\u0026rsquo;t wait to try those in real games.\nNext steps: find hot spots in the map where I die most, and from where I am killed. See you in chapter II!\n","description":"Analyzing data from my last Counter Strike (FPS) match and using it to improve","id":20,"section":"posts","tags":["Visualization","Data","Python","Machine Learning","CSGO"],"title":"Data Science in my last CS:GO match (1)","uri":"https://thebooort.github.io/posts/analyzing-data-from-my-last-csgo-match/"},{"content":"Image credit: CDC Unsplash\nEstimando R_0 de Granada (ritmo de contagio) en ventanas semanales En lugar de hacer estimaciones o predicciones (a√∫n creo que tengo que seguir leyendo m√°s sobre el tema para lanzarme) he optado por analizar el ritmo reproductivo b√°sico.\n(de Wikipedia) En epidemiolog√≠a, el n√∫mero b√°sico de reproducci√≥n (a veces llamado ritmo b√°sico de reproducci√≥n, ratio reproductiva b√°sica y denotadas por $R0$, r sub-cero) de una infecci√≥n es el n√∫mero promedio de casos nuevos que genera un caso dado a lo largo de un per√≠odo infeccioso.\nEste n√∫mero es importante porque permite darnos una idea de c√≥mo est√° evolucionando el virus y si est√° siendo √∫til las normas de confinamiento. Adem√°s nos ayuda a evaluar la evoluci√≥n de la pandemia: cuando el num√©ro baje de 1 tendremos un virus que se contagia a menos de una persona, es decir que tender√° a desaparecer en el tiempo.\nAs√≠ pues, vamos a analizar el $R_0$ en la provincia en la que resido durante esta epidemia: Granada.\nGetting the data A la hora de obtener los datos, he ido directamente a la p√°gina de la Junta de Andaluc√≠a. Es cierto que la p√°gina est√° un pel√≠n atrasada, pero es la √∫nica fuente oficial que he encontrado que permite personalizar los datos para obtener los de Granada en particular.\nLa descargar de datos es bastante sencilla, y al poco tengo un csv con los casos nuevos, los ingresos en UCI y las muertes.\nEn nuestro caso, vamos a usar los casos nuevos. Evidentemente tenemos sesgos debido a que nuestro pa√≠s no esta realizando test masivos, a√∫n as√≠, para evaluar la pandemia son interesantes.\nTambi√©n tenemos que tener en cuenta que Granada es una ciudad t√≠picamente universitaria, y que a poco de comenzar el confinamiento, muchos universitarios han regresado a su casa. Esto creo que tambi√©n ayuda a la evoluci√≥n de la enfermedad en esta provincia.\nAnalyzing the data Para anailzar los datos vamos a cambiar de Python ( mi lenguaje habitual) a R. ¬øPor qu√©? Bueno esencialmente por comodidad. Realmente R es un lenguaje bastante sencillo de manejar y posee un gran cantidad de paquetes que hacen muy sencillo el an√°lisis estad√≠stico de datos de variados or√≠genes.\nEn nuestro caso vamos a usar EpiEstim, paquete que por ejemplo, tambi√©n est√° usando ElPais (un periodico espa√±ol) en sus an√°lisis. EpiEstim se encuentra en los repositorios oficiales de R y pod√©is encontrar el art√≠culo que lo presenta aqui: A New Framework and Software to Estimate Time-Varying Reproduction Numbers During Epidemics Anne Cori, Neil M. Ferguson, Christophe Fraser and Simon Cauchemez American Journal of Epidemiology 2013.\nEste paquete se centra en el estudio de $R_t$, esat constante es el n√∫mero reproductivo instantaneo, que se puede estimar mediante el n√∫mero de nuevas infecciones generadas en tiempo $t$, frente al total de infecciosidad de los individuos contagiados en tiempo $t$. Este total se calcula siguiendo un sumatorio que usa la distribuci√≥n de probabilidad que sigue la enfermedad ( que suponemos normal) y la incidencia en $t-1$. En resumen, $R_t$ es la media de casos secundarios que cada individuo contagiado puede provocar si las condiciones se mantienen en tiempo $t$.\nHacer inferencia sobre esta variable puede ser complicado por su alta variabilidad. Por eso, el paquete plantea hacer inferencia de la misma en ventanas temporales que se solapan, para aportar mayor significaci√≥n a las estimaciones.\nLo √∫ltimo que necesitamos para hacer nuestra predicci√≥n es el intervalo serial (serial interval en ingles). El intervalo serial es el nombre que recibe el tiempo que transcurre entre los casos sucesivos en una cadena de transmisi√≥n.\nHabitualmente se estima generalmente a partir del intervalo entre los inicios cl√≠nicos, en cuyo caso es el \u0026ldquo;intervalo de serie de inicio cl√≠nico\u0026rdquo; cuando estas cantidades son observables. En principio, podr√≠a estimarse por el intervalo de tiempo entre la infecci√≥n y la transmisi√≥n posterior. En el caso particular del covid he usado esta referencia:\n Serial interval of novel coronavirus (COVID-19) infections. Hiroshi Nishiura, Natalie M. Linton,Andrei R. Akhmetzhanov  Con lo que el intervalo ser√° de 4.6 d√≠as con media de 4.8 d√≠as y desviaci√≥n t√≠pica de 2.3 d√≠as.\nPlot Obtenemos finalmente el gr√°fico. Como v√©is he representado 3 datos esenciales para nuestro an√°lisis. Por una parte un histograma b√°sico con el n√∫mero de casos que han acontecido estos d√≠as (desde que fueron representativos, recordemos que Granada tuvo 0 casos hasta muy entrada la pandemia en muchas provincias).\nEn segundo lugar aparece la estimaci√≥n del ritmo reproductivo b√°sico a lo largo del tiempo. Aunque no se aprecie posee los rangos superior e inferior del mismo. Y finalmente se muestra cual es el intervalo serial escogido como hemos comentado en la secci√≥n anterior.\nConclusions! Parecen buenas noticias! Hemos pasado ya a un estado con $R_0\u0026lt;1$, aunque son buenas noticias (implicar√≠an que a la larga la enfermedad desaparecer√≠a) hay que tener en cuenta que esto se debe a las medidas de confinamiento y que debemos ser muy cautos a√∫n.\nDeber√≠amos bajar este t√©rmino todo lo posible antes de acabar con el confinamiento, para reducir lo m√°ximo posible los rebrotes.\nA\n","description":"Estimando R_0 de Granada (ritmo de contagio) en ventanas semanales","id":21,"section":"posts","tags":["Visualization","Data","COVID19","R","Statistics","Mathematics"],"title":"¬øC√≥mo vamos? Estimando el ritmo de contagio ","uri":"https://thebooort.github.io/posts/r_0granada/"},{"content":"Image credit: Ivan Aleksic @ivalex Unsplash\n¬øC√≥mo afecta el confinamiento a los niveles de poluci√≥n? Durante la cuarentena que estamos viviendo la reducci√≥n de la movilidad de las personas es evidente.\nLigada a esta disminuci√≥n del tr√°nsito de vehiculos particulares, vehiculos de transporte p√∫blico y algunas maquinarias pertenecientes a servicios que se encuentran inactivos, muchos medios se han hecho eco de la disminuci√≥n en los niveles de poluci√≥n ambiental. Es m√°s, al ser COVID una enfermedad que afecta a las v√≠as respiratorias, ya hay algunos analisis que relacionan la poluci√≥n del aire con tasas de moratilidad mas altas por COVID.\nPor este motivo me pareci√≥ interesante estudiar el caso de la ciudad en la que resido: Granada(Espa√±a).\nLa evidencia muestra que los niveles de poluci√≥n han bajado, pero ¬øc√≥mo sabemos esto?.\nPara contestar a esto vamos a tomar dos enfoques: primero, conocer qu√© buscamos en el aire para mediar su calidad, y, segundo, conocer alguna t√©cnica que nos ofrezca los datos necesarios para nuestro an√°lisis.\n¬øQu√© buscamos? La calidad del aire se mide en relaci√≥n a la presencia y cantidad de determinados contaminantes en el aire. Los principales contaminantes monitorizados suelen estar determinados por la legislaci√≥n vigente, que tambi√©n determina qu√© baremos se utilizan para evaluar cada uno.\nAun as√≠, hay una gran variedad de contaminantes sobre los cuales existe un conseso (en cuanto a su peligrosidad) y que son monitorizados habitualmente en estaciones medidoras de calidad del aire (habitualmente en ciudades). Algunos ejemplos son:\n $NO_2$ y en general los √≥xidos de nitr√≥geno. Estos se producen como consecuencia del uso de combustibles f√≥siles como petr√≥leo, carb√≥n o gas natural. Es un contaminante muy perjudicial. $CO_2$ y $CO$ su origen antropog√©nico es debido a la combusti√≥n incompleta de materias org√°nicas (gas, carb√≥n, madera, etc.), en especial los carburantes de los autom√≥viles.  A estos habr√≠a que sumarles otros como las particulas en suspensi√≥n ($PM_5$ o $PM_10$ seg√∫n su tama√±o), el Ozono, el Di√≥xido de azufre, etc.\nDesp√∫es de consultar diversas p√°ginas y leer las noticias sobre poluci√≥n y COVID, me quedaba claro que ser√≠a muy interesante comprobar los niveles de NO_2, pues tienen una clara relaci√≥n con las actividades de transporte y su uso est√° muy extendido como par√°metro que mide la calidad del aire.\nGetting the data ¬øC√≥mo obtenemos los datos? Esencialmente los datos sobre los contaminantes se pueden encontrar en internet v√≠a dos posibles or√≠genes.\nPor una parte muchos de estos datos se originan en estaciones de medici√≥n locales. Estas permiten una obtenci√≥n de datos directamente de nucleos urbanos particulares, con una cantidad de datos relativamente peque√±a. La parte negativa es que dependes de los sensores de la estaci√≥n. En mi caso, Granada tiene varias estaciones, pero por ejemplo no pude encontrar datos de Ozono o de las part√≠culas en suspensi√≥n.\nLa otra opci√≥n es usar datos de sat√©lite. Aunque hay datos bastante actualizados sobre estas mediciones, habitualmente pesan bastante (puesto que se parten solo regiones grandes como Europa o America del Norte), y ahora mismo mi conexi√≥n de internet no da para tanto.\nParticularizando esta √∫ltima opci√≥n, si os v√©is valientes en Europa tenempos el TROPOMI, un instrumento de monitorizaci√≥n de la trposfera que tiene datos de NO2 que forma parte del Sentinel-5 de la Agencia Espacial Europea.\nFinalmente, para mi an√°lisis me dicid√≠ por usar datos de las estaciones locales, aunque solo encontr√© de NO2, al menos son datos oficiales y de un volumen manejable para tratarlos. Como extra tambi√©n tuve acceso al hist√≥rico de otros a√±os, para as√≠ compararlo. Toda la informaci√≥n la saqu√© de la Agencia Medioambiental Europea.\nAnalyzing the data La verdad es que los datos no estaban en la mejor versi√≥n posible. Adem√°s fue un poco lioso conseguirlos. A√∫n as√≠, con un poco de preprocesado obtuve lo que buscaba.\nLo √∫nico a destacar durante esta fase es la conversion a dato tipo fecha que necesitas para plotear datos pertenecientes a series temporales:\n1 2  no2_df_2020[\u0026#39;date\u0026#39;] = pd.to_datetime(no2_df_2020[\u0026#39;date_time\u0026#39;]) no2_df_2019[\u0026#39;date\u0026#39;] = pd.to_datetime(no2_df_2019[\u0026#39;date_time\u0026#39;])   En este aspecto ospuede ayudar strftime, pues que en muchas ocasiones os vais a encontrar fechas en formatos muy diferentes. Es habitual tambien que algunas librer√≠as requieran el formato de a√±o-mes-dia , o mes-dia-a√±o, para todas estas ocasiones con strftime pod√©is salir del paso.\n(El ejemplo es de otro c√≥digo pero as√≠ os hace√≠s una idea de como usarlo)\n1  df[\u0026#39;date\u0026#39;] = pd.to_datetime(df[\u0026#34;date\u0026#34;].dt.strftime(\u0026#39;%d/%m/%Y\u0026#39;))   Y bueno, como ya sab√©is empec√© a usar bokeh hace poco, asi que esto era una situaci√≥n perfecta para poner a prueba mis conocimientos.\nPlot  He marcado con verde ( no lo hab√≠a usado antes) el nivel de contaminante que la OMS considera seguro (en media al a√±o).\nPara ello he usado la funcionalidad BoxAnnotation, que adem√°s puede personalizarse un monton y se puede usar con fechas de inicio y fin:\n1 2 3 4  low_box = BoxAnnotation(top=40, fill_alpha=0.1, fill_color=\u0026#39;green\u0026#39;) top_box = BoxAnnotation(bottom=40, top=80, fill_alpha=0.1, fill_color=\u0026#39;red\u0026#39;) p1.add_layout(low_box) p1.add_layout(top_box)   A√±ad√≠ el marcaje del d√≠a en el que se inicia la cuarentena. Adem√°s saqu√© la leyenda fuera, porq dentro del gr√°fico molestaba bastante:\n1 2 3 4 5 6 7 8  from bokeh.models import Legend legend = Legend(items=[ (\u0026#34;2020\u0026#34; , [r1,r2]), (\u0026#34;2019\u0026#34; , [r3, r4]), ], location=\u0026#34;center\u0026#34;) p1.add_layout(legend, \u0026#39;right\u0026#39;)   Conclusions! Si bien es cierto que en abril hay un descenso en los dos a√±os (puede que la lluvia ayude), ven√≠amos de un febrero muy caluroso y sin apenas lluvia, por lo tanto ven√≠amos de una situaci√≥n negativa. Tambi√©n se puede observar que ya de por s√≠ nos encontrabamos en un punto muy bueno, menor al del a√±o pasado. Me llama la atenci√≥n un peque√±o repunte (quizas por el mayor uso de coches unipersonales para ir al trabajo en lugar de transporte p√∫blico?), con todo, estamos lejos de los niveles del a√±o pasado. No olvidemos tampoco que estamos representando un promedio semanal, con lo que captamos eventos que han podido pasar durante la semana completa.\nA mitad del encierro hay una gran bajada que nos deja en un nivel muy bajo y posiblemente relacionada con la mayor restricci√≥n de circulaci√≥n. Llegamos a un punto muy inferior a otros a√±os por la misma fecha, lo que parece indicar que s√≠ que se debe a causas antropol√≥gicas. Adem√°s es un buen indice de que la gente se est√° tomando en serio la cuarentena :) y que aunque sea por unos d√≠as, estamos respirando un aire m√°s limpio.\n","description":"Evoluci√≥n de los niveles de poluci√≥n en Granada durante la cuarentena","id":22,"section":"posts","tags":["Visualization","Data","COVID19","Python","Pollution","Ecology","Air Quality"],"title":"El aire que respiramos durante el confinamiento","uri":"https://thebooort.github.io/posts/pollution_levels/"},{"content":"Image credit: Javier Ezpeleta @javierezpeleta Unsplash\nDid confinement affects my sleep routine? Llevamos ya varias semanas de cuarentena y los √°nimos var√≠an mucho de un d√≠a a otro. Ultimamente han aparecido muchos art√≠culos y estudios sobre el posible impacto del confinamiento en nuestros ritmos de vida. El tema me despertaba bastante curiosidad desde el principio, y da la casualidad de que por mis otros hobbies (trail running) tengo un reloj capaz de captar algunas de mis rutinas. En particular el reloj puede realizar mediciones de sue√±o, actividad f√≠sica, pasos, etc.\nEvidentemente la actividad f√≠sica se vi√≥ afectada por el confinamiento, reduciendo mis ejercicios y mis pasos diarios. Para que os hag√°is una idea mis pasos han pasado de 14.149,2 de media diaria a s√≥lo 1869,1.\nSi bien es cierto que cuando m√°s ando, al salir a comprar para varios d√≠as, no me llevo el reloj para evitar tocarlo con las manos sucias, actualmente salgo 1 vez cada semana y media, con lo cual creo que no ayudan a la media en absoluto.\nTambi√©n hay que tener en cuenta que al hacer ejercicio en casa (algo que hago entre 1 hora / 1hora y media al d√≠a), con los movimientos que practico, el reloj tambi√©n cuenta pasos. A√∫n as√≠, creo que gracias a eso solo he llegado un d√≠a a la cifra de 4000 pasos.\nEn resumen, creo que el par√°metro del que tengo menos idea es el del sue√±o, y es uno de los que destacan para evaluar mi posible productividad, descanso, concentraci√≥n, o incluso estado an√≠mico.\nGetting the data Para obtener los datos tir√© de GPDR y solicit√© mis datos a la empresa de la cual viene mi reloj deportivo. Tardar√≥n un par de d√≠as en darme los datos, pero a su favor, gestionaron bastante bien mi solicitud.\nLos datos se distribuyen de la siguiente manera (de su p√°gina web):\n  Sue√±o profundo\nCuando pasas a la fase de sue√±o profundo, los movimientos oculares y musculares se detienen por completo. La frecuencia cardiaca y el ritmo de tu respiraci√≥n disminuyen.\n  Sue√±o ligero\nEl sue√±o ligero es la primera fase del sue√±o. Durante la fase de sue√±o ligero, los movimientos oculares y la actividad muscular se ralentizan.\n  Despierto\n  Para detectar estas fases el reloj hace uso del aceler√≥metro y el puls√≥metro. En aquellos dispositivos con ox√≠metro tambi√©n es tenido en cuenta, pero no es mi caso.\nAnalyzing the data Finalmente con los datos obtenidos, procedo a usar bokeh para un EDA. Dentro del mismo gr√°fico incluyo los datos de sue√±o total, de sue√±o profundo y sue√±o ligero.\nAdem√°s de los datos en crudo, he marcado la franja de sue√±o saludable recomendada (7-8h). Como parte del an√°lisis, he realizadao una peque√±a regresi√≥n para intentar ver qu√© tendencia segu√≠an los datos.\nSin m√°s informaci√≥n lo cierto es que son pocos datos y no es del todo representativa, pero creo que se puede intuir alguna conclusi√≥n de ella.\nConclusions! Bueno viendo los datos soy optimista. He seguido de forma adecuada un rutina de sue√±o para evitar alterar mis ciclos y ritmos diarios.\nEn parte estoy acostumbrado a realizar mis principales entrenamientos por la tarde-noche durante la semana. Estos horarios, al mantenerlos creo que me han ayudado a llegar cansado a la hora de dormir.\nEs cierto que se intuye un leve subida de las horas de sue√±o, pero con menor cantidad de sue√±o profundo. Esto puede afectar a la calidad del sue√±o, pero las variaciones son tan sumamente m√≠nimas, que no creo que tenga que preocuparme.\n","description":"Analyzing sleep patterns before and during COVID19 quarentine","id":23,"section":"posts","tags":["Visualization","Data","COVID19","Python","Machine Learning"],"title":"Did confinement affect my sleep/exercise routine?","uri":"https://thebooort.github.io/posts/analyzing-sleep-patterns-before-and-during-covid19-quarentine/"},{"content":"Bar chart race Siguiendo un poco el inter√©s que me suscita la representaci√≥n visual de datos, aprovechando la cuarentena me puse a descubrir la mejor forma de hacer una \u0026ldquo;carrera de gr√°ficos de barras\u0026rdquo;.\nEste tipo de visualizaci√≥n ha cogido fama √∫ltimamente. M√°s que por su su utilidad a la hora de analizar los datos, por su forma atractiva y visual de presentar la informaci√≥n, haci√©ndola muy apetecible al p√∫blico en general y prest√°ndose a ofrecer videos interesantes f√°ciles de consumir.\nPor esta raz√≥n, y aprovechando para adquirir nuevos conocimientos que me pueden ser √∫tiles en el futuro, me puse a replicar este tipo de visualizaci√≥n gr√°fica. El objetivo de estos posts no es solo aprender herramientas nuevas o rebuscar c√≥digos interesantes, tambi√©n ser capaz de ofrecer un gr√°fico final vistoso que sea consumible.\nOpciones Buscando por internet encontr√© varias opciones para relizar este tipo de gr√°ficos.\n Python: Python siempre sale a relucir sea cual sea tu requerimiento. En esta ocasi√≥n encontr√© posts en TowardsDataScience donde te explicaban paso a paso como conseguir el efecto. A√∫n as√≠, los resultados que ve√≠a, si bien per se eran interesantes, no llegaban al resultado final que estaba buscando. Tableau: Tableau es otro cl√°sico de la visualizaci√≥n utilizado por muchas empresas con una opci√≥n gratuita en Tableau Public con un gran potencial para realizar gr√°ficos interactivos de todo tipo y con buen acabado. Algunos de los ejemplos que v√≠ con esta herramienta no me llegaron a captar la atenci√≥n, por lo que decid√≠ dejar su aprendizaje para m√°s tarde (tengo pendiente ponerme con √©l). Flourish: Llegamos finalmente a Flourish. Flourish es otra herramienta que se puede gestionar online que ofrece muchas y variadas visualizaciones. Encontr√© esta herramienta debido a una de las gr√°ficas que se publicaron en un peri√≥dico online. Oje√°ndola me gust√≥ mucho su acabado y decid√≠ darle una oportunidad para el objetivo que ten√≠a.  Datos y preprocesado Una vez que escog√≠ Flourish, quedaba elegir qu√© datos quer√≠a representar. Como llevaba tiempo trabajando con casos de COVID-19 decid√≠ alejarme un poco de esta din√°mica y buscar alguna fuente de datos interesante.\nCasi por casualidad ese d√≠a estuve comentando los datos sobre las disminuciones de contaminaci√≥n atmosf√©rica de las grandes ciudades debido al confinamiento. Asi que las emisiones de $CO_2$ rondaban mi mente, y aunque hab√≠a relaci√≥n con el COVID19, el aspecto ecol√≥gico me atra√≠a bastante.\nEncontrar dataset buenos sobre cualquier tema es complicado, m√°s a√∫n tem√°s ecol√≥gicos/clim√°ticos. Por suerte en ensta ocasion cuento con OurWorldInData fuente de datasets de todo tipo con muchisima informaci√≥n y bien formateados. Decid√≠ elegir las emisiones de $CO_2$ por persona. Esencialmente, para calcular la contribuci√≥n del ciudadano promedio de cada pa√≠s a las emisiones totales de $CO_2$ se dividen sus emisiones totales por su poblaci√≥n, obteniendo las medidas en tonelaadas por usuario por a√±o.\nEstas emisiones juegan un papel fundamental dentro de los objetivos clim√°ticos de los a√±os venideros y, como dicen en la web: gracias a las reconstrucciones hist√≥ricas, est√°n disponibles para todo el mundo desde mediados del siglo XVIII.\nEsto nos permite captar tendencias globales, casos concretos con cifras muy altas y analizar quienes son los principales emisores de $CO_2$\nUna vez descargamos los datos y los exportamos a Flourish, tenemos un par de problemas:\n  Formato de los datos: Los datos se encuentran por fecha y pais, pero, para repesentarlos como queremos necesitamos que se muestren como una serie temporal. Con ese fin, simplemente mapeamos los distintos a√±os y creamos columnas con cada pa√≠s.\n  Datos perdidos y nuevos paises: Algunos pa√≠ses no poseen todos los datos, en estos casos hemos optado por hacer una media entre el a√±o posterior del que tenemos datos y el a√±o anterior del cual tenemos datos. No es una soluci√≥n ideal, pero como este tipo de gr√°fico no acaba representando toda la informaci√≥n, mas tarde nos cercioramos de que ninguno de los pa√≠ses en los cuales hicimos este procesado sale en el gr√°fico final. Para aquellos pa√≠ses que no tienen datos hasta un determinado a√±o, la informaci√≥n se completa con ceros.\n  Una vez solventados estos dos problemas, toqueteamos las opciones de Flourish hasta que nos convenza el dise√±o.\nResultado final Grafico interactivo Este es el resultado final. Un gran acabado, muy contento con el resultado ¬°y es interactivo!\n Video Este tipode gr√°ficos tambi√©n quedan vistosos en video, aqu√≠ os dejo el resultado con musiquita:\n  Conclusiones curiosas Por un lado destacan aquellos paises que son grandes productores de crudo, sobre todo aquellos con una poblaci√≥n peque√±a (Qatar , Kuwait\u0026hellip;). Por otra parte destaca un pico en Brunei a mediados del siglo XX, este pico da para mucho y deber√≠a escribir un post sobre √©l.\nDicho esto, creo que los resultados son mas que satisfactorios, una herramienta interesante y habilidades de manejo que pueden serme √∫tiles si necesito tirar de graficos animados e interactivos con formatos que otras librer√≠as no tienen (o cuesta mucho implementar).\n","description":"Probando Flourish para hacer graficos din√°micos","id":24,"section":"posts","tags":["Flourish","Visualization","Data","Bar Chart Race"],"title":"CO‚ÇÇ emissions per capita in history: a bar chart race","uri":"https://thebooort.github.io/posts/bar_chart/"},{"content":"COVID19 Kaggle Challenge Dentro de los challenges lanzados por Kaggle para usar los datos publicados del COVID19, los doctorandos que compartimos directora de tesis nos juntamos para probar ideas y aprender lo que pudi√©semos en el camino.\nHab√≠a varios retos o tareas en las que pod√≠amos embarcarnos, pero como nuestro inter√©s era m√°s bien acad√©mico, decidimos empezar haciendo un an√°lisis exploratorio de datos y clusterizaci√≥n. Y desde ah√≠, lo que quisi√©semos o nos diese tiempo.\nLos resultados que v√©is aqu√≠ corresponden a un enfoque muy sencillo y b√°sico de aplicaci√≥n de t√©cnicas de machine learning para crear un recomendador de art√≠culos cient√≠ficos relacionados con uno seleccionado por el usuario.\nEl objetivo es usar los titulos y abstracts de los art√≠culos para extraer \u0026ldquo;de qu√© van\u0026rdquo;. Una vez obtenido esto, se buscan art√≠culos que traten temas similares.\nPara ello seguimos estos pasos:\n EDA Text Preprocessing Tokenization vectorization LDA and Topic Extraction Recommendation system  Si quereis echarle un vistazo a el notebook (aunque esta desordenado): https://www.kaggle.com/thebooort/covid19-exploration-and-paper-recommendation\nEste post pretende presentar los principales resultados del notebook (hasta que encuentre una forma de subir los notebooks enteros), omitir√© trozos de c√≥digo que considere poco importantes.\nEDA En este aspecto, trabajando con abstract y texto, tendremos que saber cuantas palabras realmente van a entrar a nuestro sistema. Para ello una diagramas de cajas puede sernos √∫til:\n1 2 3 4 5  df[[\u0026#39;abstract_word_count\u0026#39;]].plot(kind=\u0026#39;box\u0026#39;, title=\u0026#39;Boxplot of Word Count\u0026#39;, figsize=(10,6)) plt.show() df[[\u0026#39;body_word_count\u0026#39;]].plot(kind=\u0026#39;box\u0026#39;, title=\u0026#39;Boxplot of Word Count\u0026#39;, figsize=(10,6)) plt.show()   Adem√°s, una nube de palabras tambien puede darnos una idea aproximada de qu√© palabras tienen importancia (tanto aquellas que son importante como las que no).\n1 2 3 4 5 6 7 8  for key in [\u0026#39;abstract\u0026#39;,\u0026#39;title\u0026#39;,\u0026#39;full_text\u0026#39;]: total_words = df[key].values wordcloud = WordCloud(width=1800, height=1200).generate(str(total_words)) plt.figure( figsize=(30,10) ) plt.title (\u0026#39;Wordcloud\u0026#39; + key) plt.imshow(wordcloud) plt.axis(\u0026#34;off\u0026#34;) plt.show()   Tokenizaci√≥n Para esta seccion siguiendo un c√≥digo de ajrwhite, usamos scapy. La idea es tokenizar el texto, no solo para esta parte, si no para cualquier analisis o algoritmo posterior, quedandonos con un texto depurado y palabras que realmente sean importante para etiquetar, clasificar, o mdelizar estos textos.\n1 2 3 4 5  # importamos scispacy un paquete para trabajar spaCy con textos cient√≠ficos y usamos el modelo # en_core_sci_md que contine pipeline de spacy especifica para textos biom√©dicos (50k palabras) import en_core_sci_md nlp = en_core_sci_md.load(disable=[\u0026#34;tagger\u0026#34;, \u0026#34;parser\u0026#34;, \u0026#34;ner\u0026#34;]) nlp.max_length = 2000000   Del word cloud tenemos algunas sugerencias de stop words que no son relevantes en nuestro an√°lisis.\nA√±adi√©ndolas lanzamos finalmente la tokenizacion y la aplicamos sobre nuestras columnas de texto.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  customize_stop_words = [ \u0026#39;doi\u0026#39;, \u0026#39;preprint\u0026#39;, \u0026#39;copyright\u0026#39;, \u0026#39;peer\u0026#39;, \u0026#39;reviewed\u0026#39;, \u0026#39;org\u0026#39;, \u0026#39;https\u0026#39;, \u0026#39;et\u0026#39;, \u0026#39;al\u0026#39;, \u0026#39;author\u0026#39;, \u0026#39;figure\u0026#39;, \u0026#39;rights\u0026#39;, \u0026#39;reserved\u0026#39;, \u0026#39;permission\u0026#39;, \u0026#39;used\u0026#39;, \u0026#39;using\u0026#39;, \u0026#39;biorxiv\u0026#39;, \u0026#39;fig\u0026#39;, \u0026#39;fig.\u0026#39;, \u0026#39;al.\u0026#39;, \u0026#39;di\u0026#39;, \u0026#39;la\u0026#39;, \u0026#39;il\u0026#39;, \u0026#39;del\u0026#39;, \u0026#39;le\u0026#39;, \u0026#39;della\u0026#39;, \u0026#39;dei\u0026#39;, \u0026#39;delle\u0026#39;, \u0026#39;una\u0026#39;, \u0026#39;da\u0026#39;, \u0026#39;dell\u0026#39;, \u0026#39;non\u0026#39;, \u0026#39;si\u0026#39;,\u0026#39;elsevier\u0026#39;, \u0026#39;unrestricted\u0026#39;, \u0026#39;grant\u0026#39;, \u0026#39;repository\u0026#39;, \u0026#39;original\u0026#39;, \u0026#39;acknowledgement\u0026#39;, \u0026#39;permission\u0026#39;, \u0026#39;centre\u0026#39;] for w in customize_stop_words: nlp.vocab[w].is_stop = True stop_words = nlp.Defaults.stop_words # definimos el tokenizador con las stopwords  def spacy_tokenizer(sentence): return [word.lemma_ for word in nlp(sentence) if not (word.like_num or word.is_stop or word.is_punct or word.is_space or len(word)==1)] # aplicar tokenizacion df[\u0026#39;full_text\u0026#39;] = df[\u0026#39;full_text\u0026#39;].apply(spacy_tokenizer) df[\u0026#39;abstract\u0026#39;] = df[\u0026#39;abstract\u0026#39;].apply(spacy_tokenizer) df[\u0026#39;title\u0026#39;] = df[\u0026#39;title\u0026#39;].apply(spacy_tokenizer) # eliminar espacios df[\u0026#39;full_text\u0026#39;] = df[\u0026#39;full_text\u0026#39;].apply(lambda x: \u0026#39; \u0026#39;.join(x)) df[\u0026#39;abstract\u0026#39;] = df[\u0026#39;abstract\u0026#39;].apply(lambda x: \u0026#39; \u0026#39;.join(x)) df[\u0026#39;title\u0026#39;] = df[\u0026#39;title\u0026#39;].apply(lambda x: \u0026#39; \u0026#39;.join(x))   Vectorizaci√≥n Vamos a vectorizar nuestra informaci√≥n textual ( esto es, transformar las palabras en vectores num√©ricos). Para ello podemos usar CountVectorizer o TF-IDF entre otros. Us√© estos dos por simpleza, pero CountVectorizer me di√≥ mejores resultados (CountVectorizer esencialmente vectoriza la palabra contando la frecuencia de repetici√≥n de esa palabra en los t√≠tulos o en los abstracts).\nImportando sklearn usar cualquiera de estos dos algoritmos es muy sencillo. Adem√°s, podemos a√±adir el tokenizador que queramos, en este caso el que hemos construido con spacy.\n1 2 3 4  features = 10000 tf_vectorizer = CountVectorizer(max_features=features,tokenizer = spacy_tokenizer, min_df=10) X_tf = tf_vectorizer.fit_transform(df[\u0026#39;abstract\u0026#39;]) tf_feat_name = tf_vectorizer.get_feature_names()   LDA LDA es basciamente un m√©todo estad√≠stico que busca encontrar una combinaci√≥n lineal de rasgos que caracterizan o separan dos o m√°s clases de objetos o eventos. La combinaci√≥n resultante la podemos utilizar para separar nuestros textos en grupos y obtener qu√© palabras aparecen con m√°s frecuencia dentro de esos grupos, a fin de caracterizarlos.\n1 2 3  topics = 7 lda_model = LatentDirichletAllocation(learning_method=\u0026#39;online\u0026#39;,random_state=20,n_components=topics) lda_output =lda_model.fit_transform(X_tf)   Resultado final del LDA Para visualizar LDA a parte de obtener los topics, us√© pyLDAvis. pyLDAvis es una biblioteca de Python para visualizaci√≥n interactiva de topic models (basada en el paquete R de Carson Sievert y Kenny Shirley).\nComo dicen en su web pyLDAvis est√° dise√±ado para ayudar a los usuarios a interpretar los topics en un modelo de topics que se ha ajustado a un corpus de datos textuales. El paquete extrae la informaci√≥n de un modelo de topics LDA ajustado, para ofrecer una visualizaci√≥n interactiva.\nOs lo recomiendo.\n1 2 3  # preparing for plotting pyLDAvis %matplotlib inline pyLDAvis.enable_notebook()   La visualizaci√≥n est√° dise√±ada para ser utilizada en cualquier notebook, pero tambi√©n se puede guardar en un archivo HTML independiente para compartir f√°cilmente:\n1 2 3 4  pyLDAvis.sklearn.prepare(lda_model, X_tf, tf_vectorizer) # if you want to save it  # P=pyLDAvis.sklearn.prepare(lda_model, X_tf, tf_vectorizer) # pyLDAvis.save_html(p, \u0026#39;lda.html\u0026#39;)    Pod√©is consultar el resultado como una p√°gina aparte aqui: https://thebooort.github.io/covizzz19/ , as√≠ os quit√°is de problemas si est√°is viendo este blog como theme oscuro.\nVisualizando las tem√°ticas Las tem√°ticas finales obtenidas fueron:\nTopic 0 ['protein', 'rna', 'proteins', 'activity', 'cell', 'replication', 'antiviral'] Topic 1 ['infection', 'cell', 'immune', 'infected', 'mice', 'response', 'induced', 'expression'] Topic 2 ['respiratory', 'pcr', 'samples', 'detection', 'viruses', 'assay', 'using', 'positive'] Topic 3 ['diseases', 'disease', 'review', 'development', 'health', 'research', 'based', 'new', 'use', 'infectious'] Topic 4 ['patients', 'calves', 'il', 'group', 'associated', 'days', 'cats', 'clinical', 'age'] Topic 5 ['cov', 'sars', 'protein', 'coronavirus', 'sequence', 'mers', 'human', 'genome', 'viruses'] Topic 6 ['health', 'influenza', 'risk', 'data', 'cases', 'disease', 'outbreak'] Podemos estudiar las correlaciones entre las puntuaciones de los topics de cada paper:\n1 2 3 4  # plotting results import seaborn as sns sns.heatmap(abs(ldadf[columns].corr()),annot=True) plt.title(\u0026#34; Correlation Plot\u0026#34;)   Obtenemos una correlaci√≥n baja entre topics, lo que implica que nuestra clusterizacion (si bien mejorable) no es mala.\nRecomendaciones Para obtener la recomendacion final, bastar√° con comparar las componentes que identifican a cada paper. Seleccionado uno cualquiera, calcularemos la distancia con el resto de papers y devolveremos los mas cercanos. Esta distancia la podemos definir como queramos: RMSE, Cosine similarity, etc.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  from sklearn.metrics.pairwise import cosine_distances from math import sqrt def paper_recommendation_tool(selected_paper_id): selected_paper = df_total[(df_total[\u0026#39;paper_id\u0026#39;]==selected_paper_id)] dominant_topic = int(selected_paper[\u0026#39;Major_topic\u0026#39;]) # we create another df with papers evaluation recommended_papers = df_total recommended_papers = recommended_papers.drop(selected_paper.index) x= selected_paper[columns].values.tolist() y= recommended_papers[columns].values.tolist() for indice_fila, fila in recommended_papers.iterrows(): distance = cosine_distances(x[0],y[indice_fila-1]) recommended_papers[\u0026#39;distance\u0026#39;] = distance recommended_papers = recommended_papers[[\u0026#39;paper_id\u0026#39;,\u0026#39;title\u0026#39;,\u0026#39;distance\u0026#39;,\u0026#39;Major_topic\u0026#39;]].sort_values(\u0026#39;distance\u0026#39;).head(10) return dominant_topic, recommended_papers   Probamos un caso concreto\n1 2 3 4  # Example: we are interested in 4602afcb8d95ebd9da583124384fd74299d20f5b, because his use of SPINT2 dominant_topic, recommended_papers = paper_recommendation_tool(\u0026#39;4602afcb8d95ebd9da583124384fd74299d20f5b\u0026#39;) print(dominant_topic) print(recommended_papers)   ","description":"COVID19 Kaggle Challenge: Construyendo un recomendador de art√≠culos sobre COVID19","id":25,"section":"posts","tags":["Kaggle","Coding","Data Science","COVID19","Python","Machine Learning","Recommedation Systems"],"title":"COVID19 research paper recommendation engine","uri":"https://thebooort.github.io/posts/covid_kaggle/"},{"content":"¬°Ojo! Perl6 ya \u0026ldquo;no existe\u0026rdquo;, oficalmente el lenguaje ahora se llama ¬°Raku! :)\nPerl6 Documentation Durante un breve periodo de tiempo estuve estudiando la evoluci√≥n en las contribuciones a los repositorios de c√≥digo. En muchas ocasiones se dice que este tipo de contribuciones siguen leyes de potencias, pero habitualmente esta afirmaci√≥n va apoyada √∫nicamente por un par de fits de distribuciones a los datos, sin contraste de hip√≥tesis o comparaci√≥n con otras posibles distribuciones. Aunque ya me meter√© en este costal m√°s adelante, lo cierto es que analizar las contribuciones a cualquier repositorio es siempre interesante.\nY como ya sab√©is, el tema de la visualizaci√≥n me gusta bastante, por lo que, document√°ndome para el trabajo que antes os mencionaba, encontr√© Gource.\nY como por aquel entonces tambi√©n estaba escribiendo cosillas para la documentaci√≥n de Perl6 (en particular su secci√≥n sobre simulaci√≥n de Ecuaciones diferenciales) decid√≠ probar a ver que pasaba al usar esta herramienta con ese repo.\nLos resultados gustaron mucho, y subieron el video a los updates semanales de Perl6 :).\nOs animo a usar Gource en vuestros proyectos de software libre, es un curioso gr√°fico que puede llamar la atenci√≥n de los usuarios y ser √∫til a la hora de mostrar vuestro repo (o la actividad en el mismo).\nVideo   Data Source Repositorio de la documentacion de Perl6 a fecha de creaci√≥n del video.\nSoftware usado  Gource  ","description":"Video sobre la evoluci√≥n del repo de documentaci√≥n de Perl6","id":26,"section":"posts","tags":["Github","Repository","Visualization","Perl6","Raku"],"title":"How to visualize a github repository evolution in time","uri":"https://thebooort.github.io/posts/perl6-viz/"},{"content":"Este post contin√∫a la serie sobre visualizaci√≥n del COVID-19. La motivaci√≥n para hacerla no es otra que ocupar los ratos muertos de la cuarentena para aprender a crear gr√°ficos interactivos con Bokeh.\nY de paso ofrecer un vistazo objetivo a los datos que nos llegan sobre la enfermedad. S√© que suena un poco raro pero ya que voy a estar d√°ndole vueltas al tema, tener este enfoque objetivo me ayuda a sobrellevarlo.\nEn cuanto depure los c√≥digos los subo a github y tendr√©is el enlace aqu√≠:\nCOVID19 - Gr√°ficos de Europa Para cerrar (por ahora) esta introducci√≥n que me estoy haciendo a la biblioteca Bokeh, quer√≠a aportar luz sobre la evoluci√≥n de la enfermedad por el mundo.\nNi por estudios ni por trabajo, nunca me ha tocado trabajar con datos geogr√°ficos. Es por eso que quer√≠a llenar un poco la laguna que tengo a la hora de representarlos gr√°ficamente. He visto que bokeh es un excelente recurso para eso, asi que me he lanzado a sacarle partido.\nEn esta ocasi√≥n estoy siguiendo un tutorial de Shivangi Patel.\nEl tutorial est√° estupendo y sirve no solo como introducci√≥n para plotear mapas si no tambi√©n para c√≥mo hacerlo en Bokeh y como usar Bokeh para generar un minidashboard en el que los datos vayan actualizandose.\nEsto √∫ltimo, requiere de un server que lamentable mente no tengo, asi que os dejo un su lugar un video del resultado.\nPor otra parte, he aprovechado para trabajar con geopandas y empaparme un poco del tema de datos geogr√°ficos. Lamentablemente el dataset consultado usaba un GEOID un tanto raro, que no he conseguido acoplar correactamente al archivo shapes (no usa el estandar de codificacion de pa√≠ses de 3 letras, y no coincide con los que he visto de 2 letras), con lo que la info de algunos pa√≠ses a pesar de tenerla, no est√° visible.\nEn cualquier caso, como introducci√≥n, contento con los resultados.\nGraficos Gr√°fico interactivo de casos y muertes Aqu√≠ aproveche para manejar pesta√±as y ofrecer en el mismo grafico la posibilidad de consultar ambas variables en el mundo. Prob√© con los hover, pero no me encajaron mucho y decid√≠ que esta era la mejor opci√≥n.\n Gr√°fico interactivo de casos y muertes Finalmente a√±ad√≠ la interacci√≥n al gr√°fico de manera que se acualice a cada paso. La verdad que el data set ha mostrado ser insuficiente, con muchos valores perdidos. No obstante, creo que el caso de Italia (pod√©is hacer zoom :) ) se ve bastante bien como empeora el color.\nOs dejo por aqu√≠ el video del resultado\n  Extra: El dashboard de la Johns Hopkins University Por √∫ltimo aprovecho para dejaros el dashboard de la Johns Hopkins University, que est√° muy currado y con la info al d√≠a.\n Data Source Todos los datos est√°n obtenidos de ECDC COVID-19\nLibrer√≠as usadas  Bokeh Pandas GeoPandas  Con esta parte creo que aparco de momento esta serie de COVID+Bokeh en pos de hacer alg√∫n post sobre otras herramientas. No obstante, no descarto volver en breve, el tema de la visualizaci√≥n me gusta mucho. ","description":"Graficos sobre COVID19 usando bokeh","id":27,"section":"posts","tags":["COVID19","Python","Visualization"],"title":"COVID19 + Bokeh - Mapas!","uri":"https://thebooort.github.io/posts/covid_bokeh_mapa/"},{"content":"Este post contin√∫a la serie sobre visualizaci√≥n del COVID-19. La motivaci√≥n para hacerla no es otra que ocupar los ratos muertos de la cuarentena para aprender a crear gr√°ficos interactivos con Bokeh.\nY de paso ofrecer un vistazo objetivo a los datos que nos llegan sobre la enfermedad. S√© que suena un poco raro pero ya que voy a estar d√°ndole vueltas al tema, tener este enfoque objetivo me ayuda a sobrellevarlo.\nEn cuanto depure los c√≥digos los subo a github y tendr√©is el enlace aqu√≠:\nCOVID19- Madrid vs. Andaluc√≠a Para este segundo post quise usar los datos del crecimiento en Madrid, para compararlos con Andaluc√≠a.\nLa idea aqu√≠ era ver c√≥mo de diferentes hab√≠an sido las escaladas de casos y ver c√≥mo quedaban al representarlas la una frente a la otra.\nDe paso, hacer hincapi√© en opciones para personalizar. En particular me gusta mucho la opci√≥n \u0026lsquo;mute\u0026rsquo; de la lenyenda, que te permite cambiar la opacidad de una de las l√≠neas para visualizar mejor el resto. Os animo a probarla.\n1 2 3 4 5 6  from bokeh.plotting import figure p = figure() p.legend.click_policy=\u0026#39;mute\u0026#39; # recordad que pod√©is personalizar c√≥mo act√∫a en vuestra gr√°fica p.circle(x=\u0026#39;date\u0026#39;, y=\u0026#39;cases\u0026#39;, muted_alpha = 0.2)   A√∫n no manejo los hovers bien (¬øquiz√°s es problema de c√≥mo est√° estructurado el dataset?), asi que estoy optando por poner toda la informaci√≥n. Aunque repito que no me gusta el resultado.\nPor otra parte tambi√©n quise ensayar la uni√≥n de dos gr√°ficas, que quiz√°s se ve√≠a mas explicativa. Y ojo que han cambiado la orden en Bokeh 2.0.0\n1 2 3 4 5 6  from bokeh.plotting import figure from bokeh.layouts import row p = figure() p1 = figure() # y aqui la magia show(row(p,p1))   La verdad que es bastante intuitivo. Aunque no est√© 100% contento con las gr√°ficos, aprender la librer√≠a, hacer cositas mas o menos chulas, y poder tirar de ella en el futuro, pinta muy bien.\nLo cierto es que, adem√°s, le estoy cogiendo tirria al dark mode XD.\nGr√°ficos Madrid  Andaluc√≠a  M vs A (misma gr√°fica)  M vs. A (gr√°ficas diferentes) Aqu√≠ est√±a el √∫ltimo! Creo que es el que mejor ha quedado, donde he puesto mejor los hovers, y adem√°s he ocultado la toolbar si no est√°s sobre el gr√°fico!\n Data Source Todos los datos est√°n obtenidos de Numeroteca COVID-19\nLibrer√≠as usadas  Bokeh Pandas  ","description":"Graficos sobre COVID19 usando bokeh","id":28,"section":"posts","tags":["COVID19","Python","Visualization"],"title":"COVID19 + Bokeh: Madrid vs. Andaluc√≠a","uri":"https://thebooort.github.io/posts/covid_bokeh_madrid_vs_and/"},{"content":"Este post comienza una serie sobre visualizaci√≥n del COVID-19. La motivaci√≥n para hacerla no es otra que ocupar los ratos muertos de la cuarentena para aprender a crear gr√°ficos interactivos con Bokeh.\nY de paso ofrecer un vistazo objetivo a los datos que nos llegan sobre la enfermedad. S√© que suena un poco raro pero ya que voy a estar d√°ndole vueltas al tema, tener este enfoque objetivo me ayuda a sobrellevarlo.\nEn cuanto depure los c√≥digos los subo a github y tendr√©is el enlace aqu√≠:\nCOVID19- El caso de Andaluc√≠a Comenzamos con el gr√°fico que primero vino a mi cabeza. Mi idea era obtener los datos de las provincias andaluzas, pero, hasta la fecha de subir este post, no encontraba m√°s que los de las comunidades aut√≥nomas.\nEn este caso, el ejercicio me llev√≥ a comenzar de cero con Bokeh. Un gr√°fico tan sencillo como ese sirve para iniciarte en los aspectos b√°sicos de la librer√≠a, de los cuales destaco:\n  Hovers: son las capas de visualizaci√≥n que te dan informaci√≥n sobre un punto cuando pasas el raton por encima\n  Curdoc: importada desde bokeh.io, te permite cambiar el estilo del grafico (a modo dark jeje)\n  Manejo de TOOLS: que indica que herramientas quieres que presente el gr√°fico interactivo para ser manipulado. En mi caso:\n  1 2  TOOLS = \u0026#39;crosshair,save,pan,box_zoom,reset,wheel_zoom\u0026#39; plot = figure(tools=TOOLS)    Plot de datos temporales: Hubo que hacer alg√∫n reajuste sobre el tipo de datos y luego indicarle a bokeh que estabamos trabajando con esto en su creacion:  1  plot = figure(x_axis_type=\u0026#39;datetime\u0026#39;, tools=TOOLS)   Finalmente opt√© por crear mi primer gr√°fico con puntos y l√≠neas.\nGraficos  Data Source Todos los datos est√°n obtenidos de Numeroteca COVID-19\nLibrer√≠as usadas  Bokeh Pandas  ","description":"Graficos sobre COVID19 usando bokeh","id":29,"section":"posts","tags":["COVID19","Python","Visualization"],"title":"COVID19 + Bokeh","uri":"https://thebooort.github.io/posts/covid_bokeh/"},{"content":"Hey reader, Bart here! My name is Bartolom√© Ortiz, I\u0026rsquo;m a Ph.D. student of Computer Science at Granada University (Spain). My background is Applied Mathematics (BSc in Maths, MSc in Maths and Physics). I\u0026rsquo;m currently researching Recommender Systems for complex objects, specifically with applications in nutrition, diets, and microbiome. I work as a predoctoral researcher in a European Project (Stance4health). I\u0026rsquo;m an advocate of open science and open software. In my free time, I love to talk about math, data science, computer science, skepticism and biology. I love to give talks about those things. I\u0026rsquo;m the co-host of a science podcast: The Fluxions. I also love trail running, hiking and martial arts. ","description":"There is not such thing as boring mathematics","id":32,"section":"","tags":null,"title":"About","uri":"https://thebooort.github.io/about/"}]